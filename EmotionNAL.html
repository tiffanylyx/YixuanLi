<html>
  <head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JGH78B0JBY"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-JGH78B0JBY');
</script>
     <link href="app.css" rel="stylesheet">
      <link href="structure.css" rel="stylesheet">
  </head>
    <body>
      <div class="Parent-div" style="height:100%">
        <div class="Header-div"></div>
        <!-- Sidebar loaded here -->
        <div class="Sub-div">
        <div class="Selector" id="sidebar-container"></div>
        <!-- Main content remains unchanged -->
        <div class = "Information">
          <div style = "width:100%;height:100">
          </div>
          <div class="row">
            <div class="column2">


            <img src="imgs/EmotioNal/header.jpeg" alt="" style="width: 92.5%;padding-left: 48px;">
                <br>
                    <br>
            </div>
            <div class="column1">
              <p class="Title" style="font-size:30;font-weight: bold;text-indent:0;text-align: left;padding-right: 48px;padding-left: 10px;">EmotionNAL: From Facial Expression To Sound</p>

              <h3 class="SubTitle" style="font-size:20;text-align: left;padding-right: 48px;padding-left: 10px;text-indent:0;"> Cross-Modal,
                <br>Digital Music, MAX/MSP,
              <br>Interactive Installation  </h3>
                </div>
              </div>

  <div class="row">
            <div class="column">
              <p class = "Text">

               Can a facial expression have its sound?
                <br>
                 <br>

               What does one’s face sound like?

               <br>
                <br>

              How to represent the process when I look into people's face by sound?

              <br>
              <br>


              </p>


            </div>

            <div class="column">
              <p class = "Text">

              “EmotionNAL” is a camera-based installation that captures participants’ faces in front of the camera and generate sounds with respect to that.
              It combines facial expression detection, emotion detection, signal processing, and sound mixing technologies.
              This work explores the potential of connecting facial expressions and sound together, constructing a creative method to interact with music and explore how different facial expressions and emotions can affect the sound.

              <br>
              </p>
            </div>

            <img src="imgs/EmotioNal.jpeg" alt="" class="center" style="width:60%;">

          </div>
          <div class="row">

            <div class="column">
              <p class = "Text">
                There are three steps of recognizing one frame of the audience's face: an overall impression of the whole face, the expression of the face, and the emotion behide the expression. "EmotionNAL" follows this order to process one frame of captured vide.
                <br>
                <br>

                The program first conducts facial detection by each frame to the video captured by the camera. The captured face bounding-box will be transformed directly to a sound signal after the pixel rearrangement that convert 2D image to 1D array.
                <br>
                <br>
                The program then computes the facial landmark of the detected face bounding-box as facial expression. The eyes position and mouth position will be converted to sound signal by controlling the cycle~ module.
                </p>


            </div>

            <div class="column">
             <p class = "Text">

               The emotion detection module is conducted then. The program computes each emotion's (happy, angry, sad, surprised, fealful, disgusted, netural) likelihood of one expression. The computed likelihood values control the playback parameters of the sound track.
               <br>
               <br>

               The program is built with Python (3.8).
                <br>
               - Face (Landmark) Detection: <a href = "https://github.com/ageitgey/face_recognition">link here</a>
               <br>
              <br>
              - Emotion Detection: <a href = "https://github.com/omar178/Emotion-recognition"> link here</a>
              <br>
             <br>
             - Visual and Sound Generation: MAX/MSP, Vizzie



            </div>
          </div>

          <div class="row">
            <div class="column">
              <br>
              <img src="imgs/EmotioNal/max_patch1.png" alt="" class="center" style="width:78%;">
            </div>
            <div class="column">
              <br>
                <img src="imgs/EmotioNal/max_patch4.png" alt="" class="center" style="width:79%;">


            </div>
            <img src="imgs/EmotioNal/Demo.png" alt="" class="center" style="width:83%;">
            <br>
            <br>
            <br>
            <br>



          </div>


          <script src="https://player.vimeo.com/api/player.js"></script>


          </div>

        </div>
      </div>
        </body>


        </html>
        <script>
          fetch('sidebar.html')
            .then(response => response.text())
            .then(data => {
              document.getElementById('sidebar-container').innerHTML = data;
            });
        </script>
